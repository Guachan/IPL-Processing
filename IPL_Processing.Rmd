---
title: "IPL Data LowpHOX-2"
author: "Sebastian Cantarero"
date: "8/13/2018"
output: html_document
---

```{r, eval=FALSE}
install.packages("here")
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(latex2exp)
library(readxl)
library(here) 
library(broom) 
```


## Sample Data Import


```{r import data, warning=FALSE}
path <- here("Data") # sk: hardcoded file paths are the root of all evil
samples <-
  # sk: easier within a data frame and mapping instead of map_df
  data_frame(
    filename = list.files(path, pattern = "OG.*\\.csv")[1],
    data = map(
      filename,
      ~read.csv(file.path(path, .x), as.is = TRUE) %>% as_data_frame()
    )
  )

# pulling out the information is easier with pattern recognition
pattern <- "OG(\\d+)_T(\\d+)-(\\d+)"
samples <- samples %>% unnest() %>% 
  select(Compound, Response, filename) %>% 
  filter(!grepl('N/F', Response)) %>% ##removes troublesome strings from the quant report
  filter(!grepl('Flags', Response)) %>%
  mutate(Response = as.numeric(Response)) %>% ## This was only necessary because the skip rows wasn't working as expected
  na.omit() %>%
  unique() %>%
  mutate(
    OG = str_match(filename, pattern) %>% { .[,2] },
    station = str_match(filename, pattern) %>% { .[,3] },
    depth = str_match(filename, pattern) %>% { .[,4] },
    fraction = 0.3)
```

## Import calibration standards

```{r}
# location of the report
path <- here("Data", "Compound Calibration Report_IPLS standards.xlsx")
stopifnot(file.exists(path))

# pull out calibrations
calibs <- 
  data_frame(
    sheet_index = 1:16,
    # bonus: not necessary for reading the file
    sheet_name = excel_sheets(path)[sheet_index],
    data = map(sheet_index, ~read_excel(
      path, sheet = .x, 
      range = "B34:C40",
      col_types = c("numeric", "numeric")
    ))
  )
# look at the data
calibs # still nested
calibs %>% unnest(data) # unnested
calibs %>% unnest(data) %>% # plotted
  filter(!is.na(Std_Area)) %>% 
  ggplot() + aes(Std_Amount, Std_Area, color = sheet_name) + 
  geom_smooth(method = "lm") + geom_point(size = 4)
```


## Regression Models

Non-linear regressions need useful starting values to converge. Here's the logic for how I'm going to use the linear regression to start the nls.

$$
\begin{aligned}
y &= a e^{bx} \\
\text{Taylor expansion:  } y &= a \left( 1 + bx + \frac{b^2 x^2}{2!} + ...\right) \approx a + abx \\
\text{Infer from linear regression: } a &= c \\
\text{Infer from linear regression: }b &= m/c
\end{aligned}
$$

```{r}
# using safely to catch problems with the non-linear fit
safe_nls <- safely(nls)

# calibration fit
calib_fits <- calibs %>% 
  mutate(
    lm_fit = map(
      data, 
      ~lm(Std_Area ~ Std_Amount, data = .x)
    ),
    lm_summary = map(lm_fit, glance),
    lm_coefs = map(lm_fit, tidy),
    a = map_dbl(lm_coefs, ~filter(.x, term == "(Intercept)")$estimate),
    b = a / map_dbl(lm_coefs, ~filter(.x, term == "Std_Amount")$estimate),
    nls_safe_fit = pmap(
      list(data = data, a = a, b = b),
      function(data, a, b) {
        safe_nls(Std_Area ~ a * exp(b * Std_Amount), data = data, start = list(a = a, b = b))
      }
    ),
    nls_fit_error = map_chr(
      nls_safe_fit, 
      ~if(is.null(.x$error)) {NA_character_} else {.x$error$message}),
    nls_fit = map(nls_safe_fit, "result"),
    nls_summary = map(nls_fit, ~if(!is.null(.x)) { glance(.x) } else { NULL }),
    nls_coefs = map(nls_fit, ~if(!is.null(.x)) { tidy(.x) } else { NULL })
  ) %>% select(-nls_safe_fit, -a, -b) 

# looks like exponential is not a good fit here, even with better starting values
calib_fits

# linear fit summary and coefficients
calib_fits %>% unnest(lm_summary)
calib_fits %>% unnest(lm_coefs)
```

```{r}
# use predict to plot calibration fit manually
calib_fits %>% 
  mutate(lm_predict = map(lm_fit, ~.x$model %>% mutate(Std_Area = predict(.x)))) %>% 
  ggplot() + 
  aes(Std_Amount, Std_Area, color = sheet_name) + 
  geom_line(data = function(df) unnest(df, lm_predict), mapping = aes(linetype = "lm")) +
  geom_point(data = function(df) unnest(df, data), size = 4)
```


## Apply regressions to the data!!

```{r}
linear_model_fit <- calib_fits %>% unnest(lm_coefs)
MGDG_int <- linear_model_fit$estimate[3]
MGDG_slope <- linear_model_fit$estimate[4]
PG_int <- linear_model_fit$estimate[17]
PG_slope <- linear_model_fit$estimate[18]
PE_int <- linear_model_fit$estimate[15]
PE_slope <- linear_model_fit$estimate[16]
PC_int <- linear_model_fit$estimate[25]
PC_slope <- linear_model_fit$estimate[26] ## couldn't figure out how the crossing method Seb suggested would work, might need to clean up the claibration sheet names first. This is clunky, but serves as a place holder for now


samples <- samples %>% ## This works but clunky
  arrange(Compound) %>% 
  mutate(calibrated = 
           case_when(grepl("MGDG", Compound) ~ (Response - MGDG_int)/MGDG_slope, ##apply calib based on str
                     grepl("PE", Compound) ~ (Response - PE_int)/PE_slope,
                     grepl("PG", Compound) ~ (Response - PG_int)/PG_slope,
                     grepl("PC", Compound) ~ (Response - PC_int)/PC_slope))



##test1 <- crossing(samples, linear_model_fit) %>% ## Crossing method to apply calib?
#  group_by(Compounds) %>%
 # mutate(
 #   test = if_else()
         
         

#Compounds that have a standard to calibrate are TRUE = 1 , False = 0 ## Match strings?
```


## Apply internal standard correction
```{r}
path2 <- here("Data", "Lab Notebook_2018.csv")
lab_notebook <- read_csv(path2) ##Import lab notebook with injection volumes/concentrations
 
Lowphox2_notes <- filter(
  lab_notebook, Project == "LowpHOX2") %>% 
    filter(Fraction == 0.3) %>% 
  mutate(Fraction_of_total = Total_Injected2 / (TLE_mg*1000),
         IS_Expected = Fraction_of_total*C16_PAF_ng, 
         OG = as.character(OG)) %>% 
  select(OG, Fraction_of_total, IS_Expected)## Filter out the samples of interest

##IS_Measured <- samples %>% 
  #filter(Compound = "C16PAF") %>%
 # arrange(OG, desc()) ## Code block for extracting internal standard from fullscan run for now using fake numbers
  
IS_Values <- c(.7, .8, .7, .7, .6, .5, .7, 7, .7, 0, .7) %>% 
  tbl_df() %>% 
  mutate(OG = as.character(Lowphox2_notes$OG)) %>% 
  rename(IS_Measured = value) ##Made up IS values for calibration


samples <- left_join(samples, IS_Values, by = "OG") 
samples <- left_join(samples, Lowphox2_notes, by = "OG")


calibrated_samples <- samples %>% 
    mutate(
      iscorrected = calibrated * (IS_Expected / IS_Measured),
      total = iscorrected/Fraction_of_total,
      total_L = total/200) ## Might be different volumes of water or grams of sed

##KRR: why are some of these values so negative??
```





























## Plotting calibration curves with linear and exponential fits

##Maybe just ignore this for now:
```{r}
ggplot(calib_standards, aes(x = Std_Amount, y = Std_Area)) +
  geom_point(size = 3) + 
  geom_smooth(method = "lm",aes (colour = "Linear"), se = TRUE, size = 1) +  
  scale_color_manual(name = "Fits",
                     breaks = c("Linear"),
                     values = c("blue")) +
 stat_smooth(method = "nls", formula = y ~ a*exp(b*x), start = list(a=1,b=1), ## Can't get an exponential function to plot, what values to choose for a and b?
              aes(colour = "Exponential")) +
    scale_color_manual(name = "Fits",
                     breaks = c("Linear","Exponential"),
                     values = c("red","blue")) +
  facet_wrap(~Compound, scales = 'free')


## Just the linear model for now

ggplot(calib_standards, aes(x = Std_Amount, y = Std_Area)) +
  geom_point(size = 3) + 
 geom_smooth(method = "lm", formula = y~x, family = gaussian(link = 'log')) +
    scale_color_manual(name = "Fits",
                     breaks = c("Linear","Exponential"),
                     values = c("red","blue")) +
  facet_wrap(~Compound, scales = 'free')


## How to extract linear regression intercept and coef to apply calibrations?

lin_fit <- function(dat) {
  the_fit <- lm(Std_Area ~ Std_Amount, dat)
  setNames(data.frame(t(coef(the_fit))), c("intercept", "slope")) ## Not sure I understand why this works
}

lin_fit(calib_standards %>% filter(Compound == "ARCHAEOL")) ##Test function works on 1 compound

lin_fits_df <- calib_standards %>% 
  group_by(Compound) %>% 
  do(lin_fit(.))



```
